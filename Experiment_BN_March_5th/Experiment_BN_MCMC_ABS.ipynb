{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../BO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gp import *\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from BN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and format the training and testing data\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BN = BN(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = BN.train_bayesian_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = np.array([[-15, 0.0], [10., 150.], [5., 2000.], [1., 5.], [0.01, 5.], [0.01, 5.], [0.01, 5.], [0.01, 5.], [0.01, 5.]])\n",
    "# maxeps specifies how many BOs we want to run\n",
    "maxeps = 6\n",
    "# n_iters is number of iterations we want for each run of BO\n",
    "n_iters = 100\n",
    "acqui_eva_num = 5\n",
    "greater_is_better = False\n",
    "n_pre_samples = 5\n",
    "coor_sigma = 1 * np.array([0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2])\n",
    "burn_in = 20\n",
    "input_dimension = 9\n",
    "mode = 'MAP'\n",
    "acqui_mode = 'MCMC'\n",
    "acqui_sample_num = 5\n",
    "process_sample_mode = 'abs'\n",
    "prior_mode ='normal_prior'\n",
    "likelihood_mode = 'normal_likelihood'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1 episode\n",
      "Start presampling...\n",
      "\tLearning rate: 6.41967057582e-07, training epochs: 82, batch size: 1567, n_samples: 3, prior_sigma: 3.4188635, init_sigma_weights_mu:  2.3055563, init_sigma_biases_mu: 2.849934, init_sigma_weights_rho: 0.49737722, init_sigma_biases_rho: 4.8458924\n",
      "Accuracy 0.0931428571429\n",
      "\tLearning rate: 2.07800050979e-05, training epochs: 78, batch size: 1559, n_samples: 4, prior_sigma: 2.264739, init_sigma_weights_mu:  2.8584397, init_sigma_biases_mu: 4.8499064, init_sigma_weights_rho: 1.8719058, init_sigma_biases_rho: 0.72643185\n",
      "Accuracy 0.126666666667\n",
      "\tLearning rate: 1.04713872982e-06, training epochs: 78, batch size: 1406, n_samples: 1, prior_sigma: 1.6754179, init_sigma_weights_mu:  4.1364236, init_sigma_biases_mu: 0.74344105, init_sigma_weights_rho: 0.27249765, init_sigma_biases_rho: 3.5490997\n",
      "Accuracy 0.118285714286\n",
      "\tLearning rate: 1.63699295247e-06, training epochs: 82, batch size: 1129, n_samples: 1, prior_sigma: 1.7427502, init_sigma_weights_mu:  1.93905, init_sigma_biases_mu: 3.496783, init_sigma_weights_rho: 3.7686226, init_sigma_biases_rho: 3.6813784\n",
      "Accuracy 0.0965714285714\n",
      "\tLearning rate: 0.000194157172289, training epochs: 44, batch size: 1420, n_samples: 1, prior_sigma: 4.74543, init_sigma_weights_mu:  0.15747865, init_sigma_biases_mu: 4.586526, init_sigma_weights_rho: 4.4960837, init_sigma_biases_rho: 1.5408064\n",
      "Accuracy 0.0965714285714\n",
      "Presampling finished.\n",
      "\tLearning rate: 0.000161778988972, training epochs: 84, batch size: 1990, n_samples: 1, prior_sigma: 2.8374991, init_sigma_weights_mu:  1.9085363, init_sigma_biases_mu: 4.6959467, init_sigma_weights_rho: 3.1222365, init_sigma_biases_rho: 2.2939532\n",
      "Accuracy 0.134571428571\n",
      "\tLearning rate: 2.82341165782e-06, training epochs: 42, batch size: 865, n_samples: 2, prior_sigma: 1.8879378, init_sigma_weights_mu:  4.6002617, init_sigma_biases_mu: 0.75931996, init_sigma_weights_rho: 0.204304, init_sigma_biases_rho: 4.483406\n",
      "Accuracy 0.086380952381\n",
      "\tLearning rate: 2.02616118942e-06, training epochs: 139, batch size: 990, n_samples: 2, prior_sigma: 2.245353, init_sigma_weights_mu:  3.8428464, init_sigma_biases_mu: 4.5947504, init_sigma_weights_rho: 2.8847446, init_sigma_biases_rho: 3.2751958\n",
      "Accuracy 0.142952380952\n",
      "\tLearning rate: 5.23527196455e-07, training epochs: 37, batch size: 702, n_samples: 2, prior_sigma: 3.0637648, init_sigma_weights_mu:  4.3892097, init_sigma_biases_mu: 4.7525315, init_sigma_weights_rho: 4.4972363, init_sigma_biases_rho: 4.417415\n",
      "Accuracy 0.0965714285714\n",
      "\tLearning rate: 0.506031012615, training epochs: 127, batch size: 897, n_samples: 3, prior_sigma: 4.6267886, init_sigma_weights_mu:  4.5009637, init_sigma_biases_mu: 2.8349733, init_sigma_weights_rho: 0.025873844, init_sigma_biases_rho: 2.6855993\n",
      "Accuracy 0.0965714285714\n",
      "\tLearning rate: 5.31013938355e-07, training epochs: 46, batch size: 336, n_samples: 1, prior_sigma: 4.406318, init_sigma_weights_mu:  0.13239755, init_sigma_biases_mu: 3.2499402, init_sigma_weights_rho: 3.8733659, init_sigma_biases_rho: 2.7464733\n",
      "Accuracy 0.0965714285714\n",
      "\tLearning rate: 0.0460415890607, training epochs: 66, batch size: 1920, n_samples: 3, prior_sigma: 2.4238565, init_sigma_weights_mu:  0.41052184, init_sigma_biases_mu: 0.7175773, init_sigma_weights_rho: 2.0632384, init_sigma_biases_rho: 1.1989\n",
      "Accuracy 0.115428571429\n",
      "\tLearning rate: 0.0439259492614, training epochs: 129, batch size: 306, n_samples: 4, prior_sigma: 2.7840223, init_sigma_weights_mu:  0.75490505, init_sigma_biases_mu: 3.7351182, init_sigma_weights_rho: 3.2838793, init_sigma_biases_rho: 4.8211803\n",
      "Accuracy 0.102095238095\n",
      "\tLearning rate: 0.423415553989, training epochs: 139, batch size: 55, n_samples: 2, prior_sigma: 2.3092086, init_sigma_weights_mu:  2.6827168, init_sigma_biases_mu: 1.4283918, init_sigma_weights_rho: 4.754662, init_sigma_biases_rho: 2.371886\n",
      "Accuracy 0.0965714285714\n",
      "\tLearning rate: 0.00296864805288, training epochs: 52, batch size: 252, n_samples: 4, prior_sigma: 1.0026886, init_sigma_weights_mu:  1.2062917, init_sigma_biases_mu: 2.166708, init_sigma_weights_rho: 3.684058, init_sigma_biases_rho: 3.345549\n",
      "Accuracy 0.0965714285714\n",
      "\tLearning rate: 0.10838904638, training epochs: 35, batch size: 142, n_samples: 4, prior_sigma: 1.9439715, init_sigma_weights_mu:  2.7103999, init_sigma_biases_mu: 0.8869402, init_sigma_weights_rho: 1.2983812, init_sigma_biases_rho: 4.471911\n",
      "Accuracy 0.0965714285714\n",
      "\tLearning rate: 1.3768129571e-05, training epochs: 40, batch size: 638, n_samples: 2, prior_sigma: 4.1634893, init_sigma_weights_mu:  1.2332575, init_sigma_biases_mu: 3.8064227, init_sigma_weights_rho: 0.35993946, init_sigma_biases_rho: 1.4957002\n",
      "Accuracy 0.186095238095\n",
      "\tLearning rate: 0.014326450931, training epochs: 130, batch size: 1084, n_samples: 4, prior_sigma: 0.25717196, init_sigma_weights_mu:  3.0595071, init_sigma_biases_mu: 3.9268978, init_sigma_weights_rho: 4.284227, init_sigma_biases_rho: 3.5318003\n",
      "Accuracy 0.0965714285714\n",
      "\tLearning rate: 0.000687280531185, training epochs: 138, batch size: 1309, n_samples: 1, prior_sigma: 0.2005199, init_sigma_weights_mu:  3.870829, init_sigma_biases_mu: 0.65150774, init_sigma_weights_rho: 2.9273603, init_sigma_biases_rho: 4.44235\n",
      "Accuracy 0.779428571429\n",
      "\tLearning rate: 3.11348421097e-05, training epochs: 78, batch size: 739, n_samples: 1, prior_sigma: 3.0354521, init_sigma_weights_mu:  3.3282635, init_sigma_biases_mu: 4.432396, init_sigma_weights_rho: 3.592533, init_sigma_biases_rho: 2.6264405\n",
      "Accuracy 0.0965714285714\n",
      "\tLearning rate: 1.00306375112e-05, training epochs: 47, batch size: 1783, n_samples: 4, prior_sigma: 3.3550138, init_sigma_weights_mu:  0.8210814, init_sigma_biases_mu: 2.0860233, init_sigma_weights_rho: 4.800855, init_sigma_biases_rho: 1.4255446\n",
      "Accuracy 0.0965714285714\n",
      "\tLearning rate: 5.72129013372e-05, training epochs: 132, batch size: 10, n_samples: 1, prior_sigma: 1.9611664, init_sigma_weights_mu:  2.5932539, init_sigma_biases_mu: 3.3690798, init_sigma_weights_rho: 2.3779445, init_sigma_biases_rho: 2.2063322\n"
     ]
    }
   ],
   "source": [
    "y_list = list()\n",
    "time_list = list() \n",
    "for i in range(n_iters):\n",
    "    y_list.append(list())\n",
    "\n",
    "\n",
    "for j in range(maxeps):\n",
    "    print ('Running %d episode' % (j + 1))\n",
    "    xp, yp, timep = bayesian_optimisation(coor_sigma = coor_sigma, \n",
    "                                   burn_in = burn_in, \n",
    "                                   input_dimension = input_dimension,\n",
    "                                   n_iters = n_iters, \n",
    "                                   sample_loss = loss, \n",
    "                                   bounds = bounds, \n",
    "                                   n_pre_samples = n_pre_samples, \n",
    "                                   acqui_eva_num = acqui_eva_num,  \n",
    "                                   greater_is_better=greater_is_better, \n",
    "                                   mode = mode, \n",
    "                                   acqui_mode = acqui_mode, \n",
    "                                   acqui_sample_num = acqui_sample_num,   \n",
    "                                   process_sample_mode = process_sample_mode, \n",
    "                                   prior_mode = prior_mode, \n",
    "                                   likelihood_mode = likelihood_mode)\n",
    "    y_train = yp[n_pre_samples:]\n",
    "    for idx in range(len(y_train)):\n",
    "        if idx == 0:\n",
    "            y_list[idx].append(y_train[idx])\n",
    "        else:\n",
    "            y_list[idx].append(np.min(y_train[:idx]))\n",
    "    for i in range(len(y_train)):\n",
    "        time_list[i].append(timep[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_mean_std(y_list):\n",
    "    mean_list = list()\n",
    "    std_list = list()\n",
    "    for one_list in y_list:\n",
    "        mean_list.append(np.mean(one_list))\n",
    "        std_list.append(np.std(one_list))\n",
    "    return mean_list, std_list\n",
    "mean_list_MCMC, std_list_MCMC = return_mean_std(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x_MCMC = [i+1 for i in range(len(y_list))]\n",
    "\n",
    "plt.errorbar(x_MCMC, mean_list_MCMC, yerr = std_list_MCMC, fmt = '-')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "opt_dict = {}\n",
    "opt_dict['y_list'] = y_list\n",
    "with open('BN_MCMC_ABS.pkl','wb') as file:\n",
    "    pickle.dump(opt_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BN_MCMC_ABS.pkl', 'rb') as pickle_file:\n",
    "    data1 = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
